# Reader Configuration
# Run `uv run knos init` to create your config, or copy this to reader.yaml.

llm:
  provider: "gemini"

  gemini:
    api_key: "your-google-api-key-here"
    # Or use environment variable:
    # api_key_env: "GOOGLE_API_KEY"
    model: "gemini-3-flash-preview"  # or gemini-2.5-flash, gemini-3-pro-preview

# Voice input configuration (Ctrl+R in dialogue)
# Auto-detects GPU/CPU; use smaller model on CPU for speed
voice:
  enabled: true
  # Model size: tiny, base, small, medium, large-v3
  # GPU VRAM: tiny ~1GB, base ~1GB, small ~2GB, medium ~5GB, large-v3 ~10GB
  # CPU: recommend "base" or "small" for reasonable speed
  model: "large-v3"
  language: "en"
  # Silence detection
  silence_threshold: 0.01  # RMS threshold for silence
  silence_duration: 10.0   # Seconds of silence before stopping

# Session configuration
session:
  # Cache duration in minutes (how long the reading session stays active)
  # The LLM context cache expires after this time, requiring re-upload of content
  duration_minutes: 30

# Text-to-speech configuration (Ctrl+T to toggle in dialogue)
# Set enabled: false on machines without GPU (CPU TTS may stutter)
tts:
  enabled: true
  # Backend: "kokoro" (fast, ~1GB VRAM) or "chatterbox" (high quality, ~3-4GB VRAM)
  backend: "kokoro"
  # Speed multiplier (kokoro only): 0.5 = half, 1.0 = normal, 1.5 = 50% faster
  speed: 1.0
  # Chunking settings (chars) - smaller chunks = better prosody, more pauses
  short_text_threshold: 100
  target_chunk_size: 150
  max_chunk_size: 220

  # Kokoro: fast, lightweight (~1GB VRAM)
  # Voices: af_heart, af_bella, am_michael, bf_emma, etc.
  # Full list: https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md
  kokoro:
    voice: "af_heart"

  # Chatterbox: high-quality zero-shot TTS (~3-4GB VRAM)
  # Requires: uv sync --extra chatterbox
  chatterbox:
    # "standard" (500M, more control) or "turbo" (350M, 2x faster)
    # Turbo requires: huggingface-cli login
    model: "standard"
    # Voice cloning: path to WAV file (10+ seconds recommended)
    # voice_sample: "config/voices/my-voice.wav"
    # Standard model only (ignored by turbo):
    exaggeration: 0.3  # 0.0-1.0, higher = more dramatic
    cfg_weight: 0.5    # 0.0-1.0, lower = smoother pacing
    # Both models:
    temperature: 0.8   # 0.0-1.0, lower = more consistent
    # Device: "cuda", "cpu", or omit for auto-detect
    # device: "cuda"
