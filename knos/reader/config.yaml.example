# Reader Configuration
# Copy this to config.yaml and fill in your API keys.

llm:
  provider: "gemini"

  gemini:
    api_key: "your-google-api-key-here"
    # Or use environment variable:
    # api_key_env: "GOOGLE_API_KEY"
    model: "gemini-3-flash-preview"  # or gemini-2.5-flash, gemini-3-pro-preview

# Voice input configuration (Ctrl+R in dialogue)
# Auto-detects GPU/CPU; use smaller model on CPU for speed
voice:
  enabled: true
  # Model size: tiny, base, small, medium, large-v3
  # GPU VRAM: tiny ~1GB, base ~1GB, small ~2GB, medium ~5GB, large-v3 ~10GB
  # CPU: recommend "base" or "small" for reasonable speed
  model: "large-v3"
  language: "en"
  # Silence detection
  silence_threshold: 0.01  # RMS threshold for silence
  silence_duration: 10.0   # Seconds of silence before stopping

# Session configuration
session:
  # Cache duration in minutes (how long the reading session stays active)
  # The LLM context cache expires after this time, requiring re-upload of content
  duration_minutes: 30

# Text-to-speech configuration (Ctrl+T to toggle in dialogue)
# Set enabled: false on machines without GPU (CPU TTS may stutter)
tts:
  enabled: true
  # Kokoro voices: af_heart (default), af_bella, am_michael, bf_emma, etc.
  # Full list: https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md
  voice: "af_heart"
  # Speed multiplier: 0.5 = half speed, 1.0 = normal, 1.5 = 50% faster, 2.0 = double
  speed: 1.0
